{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shopee_product_sentiment",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMy+3l+qX2w/pWKNyvv/CBd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mygetzu/shopee_product_detection/blob/master/shopee_product_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMsJiCtHvg5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "161a8563-6080-4015-964f-0e2f3474514a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "!unzip \"./gdrive/My Drive/shopee-sentiment-analysis_dataset.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./gdrive/My Drive/shopee-sentiment-analysis_dataset.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peihvUCjjk0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNVbqRo5vv9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "46ccadf6-d82b-4e5c-e240-f4af19117b31"
      },
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "df_train"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ga disappointed neat products .. Meletot Hilsn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Rdtanya replace broken glass, broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sent a light blue suit goods ga want a refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Pendants came with dents and scratches on its ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146806</th>\n",
              "      <td>146806</td>\n",
              "      <td>Excellent product quality delivery speed is ve...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146807</th>\n",
              "      <td>146807</td>\n",
              "      <td>thanks gan</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146808</th>\n",
              "      <td>146808</td>\n",
              "      <td>Awesome awesome quality merchandise value CP ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146809</th>\n",
              "      <td>146809</td>\n",
              "      <td>Nice Packing boxes made effective price .........</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146810</th>\n",
              "      <td>146810</td>\n",
              "      <td>Excellent product quality excellent product p...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146811 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        review_id                                             review  rating\n",
              "0               0  Ga disappointed neat products .. Meletot Hilsn...       1\n",
              "1               1    Rdtanya replace broken glass, broken chargernya       1\n",
              "2               2  Nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3               3      Sent a light blue suit goods ga want a refund       1\n",
              "4               4  Pendants came with dents and scratches on its ...       1\n",
              "...           ...                                                ...     ...\n",
              "146806     146806  Excellent product quality delivery speed is ve...       5\n",
              "146807     146807                                         thanks gan       5\n",
              "146808     146808   Awesome awesome quality merchandise value CP ...       5\n",
              "146809     146809  Nice Packing boxes made effective price .........       5\n",
              "146810     146810   Excellent product quality excellent product p...       5\n",
              "\n",
              "[146811 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzUSTaM7wWRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "6e346b55-c76c-418d-fb4b-7b6d8eb8cb26"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import sentiwordnet as swn, stopwords, wordnet\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')\n",
        "\n",
        "class SentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.sentimentAnalyzer = SentimentIntensityAnalyzer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        # Special Character Filtering\n",
        "        text_char_filter = self.specialchar_filtering_text(text)\n",
        "        # To lower case\n",
        "        text_lower = self.to_lowercase_text(text_char_filter)\n",
        "        # Tokenized\n",
        "        tokenized = self.tokenize_text(text_lower)\n",
        "\n",
        "        result = tokenized\n",
        "        return result\n",
        "\n",
        "    def specialchar_filtering_text(self, text):\n",
        "        # print(\"\\n======================== Special Char Filtering =========================\")\n",
        "        result = \" \".join(re.findall(\"[a-zA-Z]+\", text))\n",
        "        return result\n",
        "\n",
        "    def to_lowercase_text(self, text):\n",
        "        # print(\"\\n======================== Data case folding =========================\")\n",
        "        result = text.lower()\n",
        "        return result\n",
        "\n",
        "    def tokenize_text(self, text):\n",
        "        # print(\"[\", datetime.now(), \"] Tokenizing data....\")\n",
        "        result = nltk.pos_tag(word_tokenize(text))\n",
        "        return result\n",
        "\n",
        "    def lemmatize_text(self, text, pos_tag):\n",
        "        result = self.lemmatizer.lemmatize(text, pos_tag)\n",
        "        # print(result)\n",
        "        return result\n",
        "\n",
        "    def get_wordnet_pos_tag(self, tag):\n",
        "        tag_dict = {\n",
        "            \"J\": wordnet.ADJ,\n",
        "            \"N\": wordnet.NOUN,\n",
        "            \"V\": wordnet.VERB,\n",
        "            \"R\": wordnet.ADV,\n",
        "        }\n",
        "\n",
        "        return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "    def get_vader(self, word):\n",
        "        return self.sentimentAnalyzer.polarity_scores(word)\n",
        "\n",
        "    def get_vader_result(self, text):\n",
        "        text_preprocessed = self.preprocess_text(text)\n",
        "        vader = self.sentimentAnalyzer.polarity_scores(text_preprocessed)\n",
        "\n",
        "        sentences_result = 0\n",
        "        total = 0\n",
        "\n",
        "        word_count = 0\n",
        "        for word in text_preprocessed:\n",
        "            if word[0] not in self.stop_words:\n",
        "                try:\n",
        "                    degree = self.get_vader(word)\n",
        "                    result = self.get_aggregation(\n",
        "                        degree['pos'], degree['neg'], degree['neu'])\n",
        "                    # print(\"Result = \", result)\n",
        "\n",
        "                    if result != None:\n",
        "                        word_count += 1\n",
        "\n",
        "                    sentences_result += result\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        if word_count > 0:\n",
        "            sentences_result = sentences_result / word_count\n",
        "        else :\n",
        "            sentences_result = 0\n",
        "\n",
        "        return (sentences_result - (-1)) / 2\n",
        "\n",
        "\n",
        "    def get_wordnet_degree(self, word):\n",
        "        pos_tag = self.get_wordnet_pos_tag(word[1][0])\n",
        "\n",
        "        lemmatized = self.lemmatize_text(word[0], pos_tag)\n",
        "        synset = swn.senti_synset('{0}.{1}.03'.format(lemmatized, pos_tag))\n",
        "\n",
        "        return {\n",
        "            'positive': synset.pos_score(),\n",
        "            'negative': synset.neg_score(),\n",
        "            'objective': synset.obj_score()\n",
        "        }\n",
        "\n",
        "    def get_aggregation(self, pos, neg, obj):\n",
        "        pos_wordnet = 0\n",
        "        neg_wordnet = 0\n",
        "        result = 0\n",
        "\n",
        "        if pos > neg:\n",
        "            pos_wordnet = pos / (pos + neg)\n",
        "            result = pos_wordnet - (obj * pos_wordnet)\n",
        "        elif pos < neg:\n",
        "            neg_wordnet = neg / (pos + neg) * -1\n",
        "            result = neg_wordnet - (obj * neg_wordnet)\n",
        "        else:\n",
        "            result = 0\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_sentiwordnet(self, text):\n",
        "        sentences_result = 0\n",
        "        total = 0\n",
        "\n",
        "        # print(\"Review : \", text)\n",
        "\n",
        "        text_preprocessed = self.preprocess_text(text)\n",
        "\n",
        "        word_count = 0\n",
        "        for word in text_preprocessed:\n",
        "            if word[0] not in self.stop_words:\n",
        "                try:\n",
        "                    degree = self.get_wordnet_degree(word)\n",
        "                    result = self.get_aggregation(\n",
        "                        degree['positive'], degree['negative'], degree['objective'])\n",
        "                    # print(\"Result = \", result)\n",
        "\n",
        "                    if result != None:\n",
        "                        word_count += 1\n",
        "\n",
        "                    sentences_result += result\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        # print(\"[\", datetime.now(), \"] Word count :\", word_count)\n",
        "        if word_count > 0:\n",
        "            sentences_result = sentences_result / word_count\n",
        "        else :\n",
        "            sentences_result = 0\n",
        "\n",
        "        # print(\"[\", datetime.now(), \"] Sentences result :\", sentences_result)\n",
        "        return (sentences_result - (-1)) / 2"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mNVZoIpw41J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "38009aa5-63b3-4365-c54c-13b3fd4c7464"
      },
      "source": [
        "# Test sentiment\n",
        "sentiment_analyzer = SentimentAnalyzer()\n",
        "wordnet_score = sentiment_analyzer.get_sentiwordnet(df_train.iloc[0]['review'])\n",
        "vader_score = sentiment_analyzer.get_vader_score(df_train.iloc[0]['review'])\n",
        "normalized_wordnet = (wordnet_score - (-1)) / 2\n",
        "print(\"Normalized wordnet : \", wordnet_score)\n",
        "print(\"Normalized vader : \", vader_score)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-aa3a83e65804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msentiment_analyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwordnet_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentiwordnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvader_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vader_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnormalized_wordnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwordnet_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Normalized wordnet : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordnet_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SentimentAnalyzer' object has no attribute 'get_vader_score'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJZT-bYi1P5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9b599b17-4480-4ee5-bd19-9c2e8f29da02"
      },
      "source": [
        "df_train['wordnet_score'] = df_train.apply(lambda x : sentiment_analyzer.get_sentiwordnet(x['review']), axis=1)\n",
        "df_train['vader_score'] = df_train.apply(lambda x : sentiment_analyzer.get_vader(x['review']), axis=1)\n",
        "df_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>wordnet_score</th>\n",
              "      <th>vader_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ga disappointed neat products .. Meletot Hilsn...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.4215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Rdtanya replace broken glass, broken chargernya</td>\n",
              "      <td>1</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>-0.7351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.8834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sent a light blue suit goods ga want a refund</td>\n",
              "      <td>1</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.0772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Pendants came with dents and scratches on its ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.3612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146806</th>\n",
              "      <td>146806</td>\n",
              "      <td>Excellent product quality delivery speed is ve...</td>\n",
              "      <td>5</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.8775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146807</th>\n",
              "      <td>146807</td>\n",
              "      <td>thanks gan</td>\n",
              "      <td>5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.4404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146808</th>\n",
              "      <td>146808</td>\n",
              "      <td>Awesome awesome quality merchandise value CP ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>0.9323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146809</th>\n",
              "      <td>146809</td>\n",
              "      <td>Nice Packing boxes made effective price .........</td>\n",
              "      <td>5</td>\n",
              "      <td>0.572917</td>\n",
              "      <td>0.7096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146810</th>\n",
              "      <td>146810</td>\n",
              "      <td>Excellent product quality excellent product p...</td>\n",
              "      <td>5</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.8908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>146811 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        review_id  ... vader_score\n",
              "0               0  ...      0.4215\n",
              "1               1  ...     -0.7351\n",
              "2               2  ...      0.8834\n",
              "3               3  ...      0.0772\n",
              "4               4  ...      0.3612\n",
              "...           ...  ...         ...\n",
              "146806     146806  ...      0.8775\n",
              "146807     146807  ...      0.4404\n",
              "146808     146808  ...      0.9323\n",
              "146809     146809  ...      0.7096\n",
              "146810     146810  ...      0.8908\n",
              "\n",
              "[146811 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG15q7wB7fZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "00846549-b887-4c6b-819f-5de61f68f895"
      },
      "source": [
        "df_test['wordnet_score'] = df_test.apply(lambda x : sentiment_analyzer.get_sentiwordnet(x['review']), axis=1)\n",
        "df_test['vader_score'] = df_test.apply(lambda x : sentiment_analyzer.get_vader(x['review']), axis=1)\n",
        "df_test"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>wordnet_score</th>\n",
              "      <th>vader_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Great danger, cool, motif and cantik2 jg model...</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.7357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>One of the shades don't fit well</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>-0.4449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Very comfortable</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.5563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Fast delivery. Product expiry is on Dec 2022. ...</td>\n",
              "      <td>0.482143</td>\n",
              "      <td>-0.6597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>it's sooooo cute! i like playing with the glit...</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.9059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60422</th>\n",
              "      <td>60423</td>\n",
              "      <td>Product has been succesfully ordered and shipp...</td>\n",
              "      <td>0.567308</td>\n",
              "      <td>0.6808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60423</th>\n",
              "      <td>60424</td>\n",
              "      <td>Opening time a little scared. Fear dalemnya de...</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>-0.7331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60424</th>\n",
              "      <td>60425</td>\n",
              "      <td>The product quality is excellent. The origina...</td>\n",
              "      <td>0.610577</td>\n",
              "      <td>0.9390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60425</th>\n",
              "      <td>60426</td>\n",
              "      <td>They 're holding up REALLY well also .</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.4812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60426</th>\n",
              "      <td>60427</td>\n",
              "      <td>Rapid response and detail ...\\nThanks gan, the...</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.7506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60427 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       review_id  ... vader_score\n",
              "0              1  ...      0.7357\n",
              "1              2  ...     -0.4449\n",
              "2              3  ...      0.5563\n",
              "3              4  ...     -0.6597\n",
              "4              5  ...      0.9059\n",
              "...          ...  ...         ...\n",
              "60422      60423  ...      0.6808\n",
              "60423      60424  ...     -0.7331\n",
              "60424      60425  ...      0.9390\n",
              "60425      60426  ...      0.4812\n",
              "60426      60427  ...      0.7506\n",
              "\n",
              "[60427 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJi1tRMrHuH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalization\n",
        "normalization = preprocessing.MinMaxScaler()\n",
        "df_train[['wordnet_score', 'vader_score']] = normalization.fit_transform(df_train[['wordnet_score', 'vader_score']])\n",
        "df_test[['wordnet_score', 'vader_score']] = normalization.fit_transform(df_test[['wordnet_score', 'vader_score']])\n",
        "\n",
        "X_train = df_train[['wordnet_score', 'vader_score']]\n",
        "X_test = df_test[['wordnet_score', 'vader_score']]\n",
        "y_train = df_train['rating']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5B5xvgJ4ZzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "c6b6e8d6-5f5c-4686-b242-d12098a8243d"
      },
      "source": [
        "# KNN Method\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "y_predict = knn.predict(X_test)\n",
        "print(df_test)\n",
        "\n",
        "df_test['rating'] = df_test.apply(lambda x : y_predict[x.name], axis=1)\n",
        "\n",
        "submission = df_test[['review_id', 'rating']]\n",
        "submission.to_csv('sample_data/submission_product_sentiment.csv', index=None)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       review_id  ... rating\n",
            "0              1  ...      5\n",
            "1              2  ...      1\n",
            "2              3  ...      4\n",
            "3              4  ...      1\n",
            "4              5  ...      5\n",
            "...          ...  ...    ...\n",
            "60422      60423  ...      3\n",
            "60423      60424  ...      1\n",
            "60424      60425  ...      5\n",
            "60425      60426  ...      4\n",
            "60426      60427  ...      3\n",
            "\n",
            "[60427 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcVYEoJXAI4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "dd08e794-0ae7-4edf-9bf9-a4b89d93e903"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_predict = model.predict(X_test)\n",
        "print(df_test)\n",
        "\n",
        "df_test['rating'] = df_test.apply(lambda x : y_predict[x.name], axis=1)\n",
        "\n",
        "submission = df_test[['review_id', 'rating']]\n",
        "submission.to_csv('sample_data/submission_product_sentiment_boost.csv', index=None)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       review_id  ... rating\n",
            "0              1  ...      3\n",
            "1              2  ...      1\n",
            "2              3  ...      3\n",
            "3              4  ...      1\n",
            "4              5  ...      5\n",
            "...          ...  ...    ...\n",
            "60422      60423  ...      3\n",
            "60423      60424  ...      1\n",
            "60424      60425  ...      5\n",
            "60425      60426  ...      4\n",
            "60426      60427  ...      5\n",
            "\n",
            "[60427 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHmuOX8mBQG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}